{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# **Réseau de neurone de convolution**\n",
    "\n",
    "Dans cette approche nous testerons un réseau de neurone de convolution afin de résudre le problème posé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Create a CNN for MNIST\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# Load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')  # permet plus tard d'utiliser Conv2D\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')  # permet plus tard d'utiliser Conv2D\n",
    "# normalize\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "# one hot encode output\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\nEpoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25s - loss: 0.3935 - acc: 0.8770 - val_loss: 0.0880 - val_acc: 0.9720\nEpoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23s - loss: 0.0896 - acc: 0.9723 - val_loss: 0.0509 - val_acc: 0.9840\nEpoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21s - loss: 0.0656 - acc: 0.9804 - val_loss: 0.0345 - val_acc: 0.9885\nEpoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20s - loss: 0.0539 - acc: 0.9837 - val_loss: 0.0342 - val_acc: 0.9882\nEpoch 5/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21s - loss: 0.0454 - acc: 0.9856 - val_loss: 0.0315 - val_acc: 0.9899\nEpoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21s - loss: 0.0413 - acc: 0.9869 - val_loss: 0.0265 - val_acc: 0.9904\nEpoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21s - loss: 0.0363 - acc: 0.9880 - val_loss: 0.0317 - val_acc: 0.9897\nEpoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21s - loss: 0.0326 - acc: 0.9897 - val_loss: 0.0264 - val_acc: 0.9914\nEpoch 9/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20s - loss: 0.0307 - acc: 0.9901 - val_loss: 0.0254 - val_acc: 0.9920\nEpoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20s - loss: 0.0276 - acc: 0.9906 - val_loss: 0.0271 - val_acc: 0.9918\nEpoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20s - loss: 0.0252 - acc: 0.9917 - val_loss: 0.0269 - val_acc: 0.9914\nEpoch 12/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20s - loss: 0.0238 - acc: 0.9920 - val_loss: 0.0264 - val_acc: 0.9917\nEpoch 13/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20s - loss: 0.0235 - acc: 0.9925 - val_loss: 0.0259 - val_acc: 0.9916\nEpoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20s - loss: 0.0214 - acc: 0.9924 - val_loss: 0.0295 - val_acc: 0.9910\nEpoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20s - loss: 0.0210 - acc: 0.9927 - val_loss: 0.0235 - val_acc: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large CNN Error: 0.78%\n"
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# build model\n",
    "model = model()\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=200, verbose=2)\n",
    "# final evaluation\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9922\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Résultat **\n",
    "Nous obtenons donc un taux de réponse juste de plus de 99% ce qui constitue un très bon résultat. Ce résultat pourrait être amélioré en modifiant le nombre de neurone dans les différentes couches du réseau de neurone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}